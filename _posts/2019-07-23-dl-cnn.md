---
layout:     post
title:      "Deep Learning"
subtitle:   "CNN"
date:       2019-07-23
author:     "btyzkelili"
header-img: "img/post-bg-nextgen-web-pwa.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Deep Learning
---  
# 卷积网络  

卷积网络（convolutional network）(LeCun, 1989)，也叫做卷积神经网络（con-volutional neural network, CNN），
是一种专门用来处理具有类似 **网格结构** 的数据的神经网络。例如时间序列数据（可以认为是在时间轴上有规律地采样形成的一维网格）
和图像数据（可以看作是二维的像素网格）。卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。

---
## 1. 卷积运算
从数学上讲，卷积与加减乘除一样是一种运算，其运算的根本操作是将两个函数的其中一个先平移，然后再与另一个函数相乘后的累加和。
![](/img/dl_cnn/3.gif)    
我们称(f * g)(n)为f,g的卷积

其连续的定义为：
![](/img/dl_cnn/4.png)    

其离散的定义为:
![](/img/dl_cnn/5.png)  

这两个式子有一个共同的特征：f和g的参数和为卷积的参数n
也就是说，如果我们定义f的参数为x，g的参数为y，那么x+y = n，x轴和y轴组成的平面定义为f(x)g(y)，那么卷积函数就是沿着x+y=n的直线求积分，
就好比沿着平面的45°角卷起来，从二维平面变成了一维，一维上每个点是卷积参数n等于该值的结果，也就是函数f(x)和g(y)在x+y=n时的乘机后的累加和：
![](/img/dl_cnn/1.gif) ![](/img/dl_cnn/2.gif)    

所以，**卷积的本质就是求加权求和**,CNN网络中使用的卷积不是严格意义上的数学上的卷积

## 2. Why CNN for Image?
图片有三个特点：
![](/img/dl_cnn/6.png)  
1. 侦测某些部分被是否存在，不需要整张图片,eg:找鸟嘴--->convolution layer  
![](/img/dl_cnn/7.png)  
2. 同样含义的部分有可能出现在图片上多个部分,eg:多个鸟嘴--->convolution layer  
![](/img/dl_cnn/8.png)  
3. 把图片的几行几列去掉对于图片没有很大影响--->max pooling  

## 3. CNN架构：
![](/img/dl_cnn/9.png)  

#### 3.1 Convolution
![](/img/dl_cnn/10.png)  
黑白图片只有长宽没有高度，一个filter与黑白image的一部分做内积(卷积/加权求和)，filter以stride(步长)大小移动，在下图中，filter的斜线部分权值更大，所以，当图片中有斜线形状的部分出现，内积的结果值更大，也就找到了图片中含斜线的部分
![](/img/dl_cnn/11.png)  
**一个filter就是一个channel**, 多个filter做上面同样的操作, 得到feature ma, 多个filter的结果叠在一起有高度，这也是为什么通过一层卷层之后，图片变小但是变厚
![](/img/dl_cnn/12.png)  
对于彩色图片，高度表示RGB，同样filter也要有高度

对应神经网络/对比全连接：
![](/img/dl_cnn/13.png)  
将图片拉直作为输入，filter上的值对应这些输入的权重,也就是要训练的对象，filter与图片内积的结果就是神经元的输出，得到卷积结果的神经元只用了一部分输入,使得与全连接相比训练更少的参数。

![](/img/dl_cnn/14.png)  
filter移动之后，就相当于是下一个神经元，由于只是filter的移动，所以filter上的值没有改变，也就是说它和前一个神经元共享这部分权值,只是对应不同的输入，这使得训练的参数更更少。

#### 3.2 Max Pooling
![](/img/dl_cnn/16.png)  
![](/img/dl_cnn/17.png)  
把从filter得到的更小的图片，每4个为一组(或其他划分方式)，用里面最大的(或其他方式)代替整个组，得到更小的图片

#### 3.3 Flatten
![](/img/dl_cnn/15.png)  
将max pooling得到的图片拉直，输入到全连接中，之后可以进行分类等操作

#### 3.4 CNN in Keras
![](/img/dl_cnn/18.png)  

![](/img/dl_cnn/19.png)  
输入是一个1(黑白) * 28(长) * 28(宽)大小的图片，经过有25个3 * 3的filter的卷积层，变为25(25个filter) * 26 * 26(3 * 3扫过28 * 28的图片之后得到26 * 26)的图片，每个filter有9个参数(3 * 3的filter),再经过2 * 2 的max pooling，变为25 * 13 * 13大小的图片；接着通过第二个convolution和max pooling,由于上一层图片高度是25，所以是50个25 * 3 * 3的filter, 图片变为50(50个filter就是50个channel,每个的高度为25) * 11 * 11, 所以每个filter有25 * 3 * 3=225个参数,再次通过2 * 2的max pooling, 得到50 * 5 * 5大小的图片。

![](/img/dl_cnn/20.png)  

#### 3.5 CNN.py(Keras)
```python3
"""
To know more or get code samples, please visit my website:
https://morvanzhou.github.io/tutorials/
Or search: 莫烦Python
Thank you for supporting!
"""

# please note, all tutorial code are running under python3.5.
# If you use the version like python2.7, please modify the code accordingly

# 6 - CNN example

# to try tensorflow, un-comment following two lines
# import os
# os.environ['KERAS_BACKEND']='tensorflow'

import numpy as np
np.random.seed(1337)  # for reproducibility
from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten
from keras.optimizers import Adam

# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called
# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )

(X_train, y_train), (X_test, y_test) = mnist.load_data()

# data pre-processing
X_train = X_train.reshape(-1, 1,28, 28)/255.
X_test = X_test.reshape(-1, 1,28, 28)/255.
y_train = np_utils.to_categorical(y_train, num_classes=10)
y_test = np_utils.to_categorical(y_test, num_classes=10)

# Another way to build your CNN
model = Sequential()

# Conv layer 1 output shape (32, 28, 28)
model.add(Convolution2D(
    batch_input_shape=(None, 1, 28, 28),
    filters=32,
    kernel_size=5,
    strides=1,
    padding='same',     # Padding method
    data_format='channels_first',
))
model.add(Activation('relu'))

# Pooling layer 1 (max pooling) output shape (32, 14, 14)
model.add(MaxPooling2D(
    pool_size=2,
    strides=2,
    padding='same',    # Padding method
    data_format='channels_first',
))

# Conv layer 2 output shape (64, 14, 14)
model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))
model.add(Activation('relu'))

# Pooling layer 2 (max pooling) output shape (64, 7, 7)
model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))

# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)
model.add(Flatten())
model.add(Dense(1024))
model.add(Activation('relu'))

# Fully connected layer 2 to shape (10) for 10 classes
model.add(Dense(10))
model.add(Activation('softmax'))

# Another way to define your optimizer
adam = Adam(lr=1e-4)

# We add metrics to get more results you want to see
model.compile(optimizer=adam,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

print('Training ------------')
# Another way to train the model
model.fit(X_train, y_train, epochs=1, batch_size=64,)

print('\nTesting ------------')
# Evaluate the model with the metrics we defined earlier
loss, accuracy = model.evaluate(X_test, y_test)
print('\ntest loss: ', loss)
print('\ntest accuracy: ', accuracy)
```
## 4. Applicaton

#### 4.1 Deep Dream
![](/img/dl_cnn/21.png)  
将CNN学到的filter扩大，让的更正，负的更负，也就是放大网络看到的：
![](/img/dl_cnn/22.png)  

#### 4.2 Deep Style
![](/img/dl_cnn/23.png)  
找一张图片，使得其CNN处理之后既像图片1又像图片2

#### 4.3 alpha go
![](/img/dl_cnn/24.png)  
围棋可以找小的有意义pattern，这些pattern也可能出现在多处(convolution)，但是将围棋的长宽几行去掉(max pooling)怎么会不影响围棋的处理效果呢？
实际上，alpha go并没有使用max pooling--->要根据实际应用来使用CNN
 
#### 4.4 Speech
![](/img/dl_cnn/25.png)  
横轴为时间，纵轴为声音的频率，使用CNN时，对于所选的一块image部分，filter的宽和image一样，从上扫到下，而不时横着扫过(考虑时间)，这是因为CNN之后还接其他网络(LSTM等)，这些网络会考虑事件前后因素，在CNN中考虑不会有太大帮助，对于男声和女声，只是频率上有所差别，相同的部分可能出现在上下两块，适用于CNN

#### 4.5 Text
![](/img/dl_cnn/26.png)  
对于embedding组成'图片'，它的每一列都是独立的，用红框的方法扫过没有任何意义。

综上来看，我们要**根据实际问题，来合理的设计使用CNN**
