---
layout:     post
title:      "Deep Learning"
subtitle:   "GCN"
date:       2019-07-24
author:     "btyzkelili"
header-img: "img/post-bg-nextgen-web-pwa.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Deep Learning
---  
# 图卷积网络
设图有N个结点，每个节点有各自的特征，组成N * D维的特征矩阵X，各结点之间形成N * N维的邻接矩阵A，

网络层与层之间传播的方式是：
![](/img/dl_gcn/1.png)  
A˜：A + I<sub>N</sub>(单位矩阵)
D˜：A˜的度矩阵(degree matrix)，![](/img/dl_gcn/2.png)  
H<sup>l</sup>：第l层的输入特征，对于输入层，H=X
σ：非线性激活函数
其中，D˜<sup>-1/2</sup>A˜D˜<sup>-1/2</sup>可以预先计算出来，因为D˜由A˜得到，A˜由A和I得到，A是输入。

![](/img/dl_gcn/3.png)![](/img/dl_gcn/3.png)  
X和A作为网络的输入，整个训练过程中，**A不变**，输入结点的特征经过GCN之后从X变为Z，对所有带标签的节点计算cross entropy损失函数来调整网络参数，使得输出的Z更好的描述结点

## 为什么GCN的层与层传播方式是这样设置的？
假设图中没有自环，即A<sub>ii</sub>=0：
GCN本质是通过网络(graph)中的关联信息(edge)来得到节点的特征(node represent)
假如说，我们要根据X<sub>i</sub>的朋友圈来预测X<sub>i</sub>的工资：
![](/img/dl_gcn/6.png)  
1. 首先考虑，所有朋友的工资的平均值就是自己的工资，所以(平均数值需要对加和的系数归一化即可，后面完善)：
![](/img/dl_gcn/5.png)  
如果是无权图，A<sub>ij</sub>是0/1，如果j不在neighbor(i)中，A<sub>ij</sub>=0,所以，上式可写为：
![](/img/dl_gcn/7.png)  
矩阵形式：
![](/img/dl_gcn/8.png)  
2. 平均方法有一个问题：没有考虑到我们与不同朋友的亲密度是不同的，比如，我们都认识马化腾，但是张志东与马化腾的亲密度要比我们和马化腾的亲密度高得多。因此，可以预测张志东的工资比我们更接近马化腾。
严谨来说，上式忽略了边的权重。我们只需要把无权图(A<sub>ij</sub>只能为0或1)变为有权图(A<sub>ij</sub>可以为任何数)。有很多工作都是在研究如何更巧妙的构建有权图(比如用节点间的相似度等),我们仍可以用上式表达加权平均:
![](/img/dl_gcn/8.png)  
3. 加权平均法也一个小问题：它没有考虑到『你可能很会吹牛』。比如，虽然我们能力和朋友们差不多，但是我们很会吹牛逼所以特别受到领导赏识（误）被提拔的很快。这时，可以预测我们的工资会比我们的朋友要高。
严谨来说，上式忽略了节点自身的特征。因此一般我们会通过添加一个自环把节点自身特征加回来：
![](/img/dl_gcn/9.png)  
通过A + I操作，可以将结点自身的特征加回来
4. 从另一个角度看，有一些任务对工资的绝对值不感兴趣。比如，『检测凤凰男防止相亲采坑』的任务。凤凰男可能会因为某些机遇工资飙升，但是他的朋友圈工资水平仍然不高，从而产生较大的贫富差距。而对于富二代而言，他们的朋友圈通常也是富二代，贫富差距较小。
严谨来说，有些任务可能更关注相邻节点间的“差分”。因此我们一般会用拉普拉斯矩阵L=D-A来做，其中D是图的度矩阵，节点的“差分”可以表示为：
![](/img/dl_gcn/10.png)  
从化简后的公式可以看到，通过拉普拉斯矩阵的相乘，我们求得是以边为权、节点特征的差分。
5. 归一化问题，无论是A+I还是D-A，其实存在一个重大的问题，我们求的是和而不是平均。我们可能会面临『大佬可能没有多少朋友』的问题。在聚合后，即使大佬的朋友圈都是高收入群体，也没办法超过一个拥有低端朋友圈的交际花。




