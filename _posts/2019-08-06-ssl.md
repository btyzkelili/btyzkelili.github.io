---
layout:     post
title:      "Deep Learning"
subtitle:   "Tips for Deep Learning"
date:       2019-08-02
author:     "btyzkelili"
header-img: "img/post-bg-nextgen-web-pwa.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Deep Learning
---  
## 1. Introduction
![](/img/lhy_ml/ssl-1.png)  ![](/img/lhy_ml/ssl-1.png)  
我们缺的不是数据，而是有标签的数据，无标签的数据，在一定的假设下，其分布可以告诉我们一些信息，这是半监督起作用的基础

## 2. ssl for Generative model
![](/img/lhy_ml/ssl-3.png)  
用有标签的数据初始化μ等参数，计算得到model，用这个model预测无标签的数据，无标签的数据可能属于class1可能属于class2，根据这个可能性计算新的μ，
更新model

## 3. Assumption

### Low-density Separation"非黑即白"
![](/img/lhy_ml/ssl-8.png)  
low-density表示分类的边界是稀疏的

#### self-training
![](/img/lhy_ml/ssl-4.png)  
self-train对regression没有作用，因为regression是预测一个实数，这个实数无法更新model

![](/img/lhy_ml/ssl-5.png)  
如果使用NN，对比generation model，soft label不起作用，因为新的model的学习目标是旧model的输出，是无法学习的，但是generation model可以，是
因为它是通过更新μ来更新model的

* Entropy-based Regularization
![](/img/lhy_ml/ssl-6.png)  
有时直接认为p=0.7就是class1(图中例子)不太可靠，可以使用Entropy-based Regularization方式，loss function要求，有标签的尽可能和标签结果相同，无标签得到的类别可能性尽可能集中

#### Semi-supervised SVM
![](/img/lhy_ml/ssl-7.png)  
对所有数据穷举所有可能的分类方法，用SVM找到每个分法的分类方式，最后比较这些分类方式，找到有标签分类正确并且margin最大的划分方式

### Smoothness
![](/img/lhy_ml/ssl-10.png)  ![](/img/lhy_ml/ssl-9.png)  
直接看会发现第二个2和3更像，但是第一个2到第二个2之间有过渡，而第二个2和3之间没有，不smooth，所以我们认为第二个2是2而不是3，这就是Smoothness Assumption

#### Cluster and label
![](/img/lhy_ml/ssl-11.png)  
两个橘色的点之间有其他很多点，他们俩可以过渡过去，而橘色的点与绿色的点中间点少，难以跨过去

#### Graph-based Approach
![](/img/lhy_ml/ssl-12.png)  
通过基于图的方法来分类，有时数据自然表示为图，有时需要自己构建图
![](/img/lhy_ml/ssl-13.png)  
构建图的方法



