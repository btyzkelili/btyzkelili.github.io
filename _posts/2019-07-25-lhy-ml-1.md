---
layout:     post
title:      "Machine Learning"
subtitle:   "lhy"
date:       2019-07-25
author:     "btyzkelili"
header-img: "img/post-bg-nextgen-web-pwa.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Machine Learning
---  
## 0. Machine Learning
![](/img/lhy_ml/1.png)  
在有机器学习之前，实现人工智能的方式：hand-crafied rules，成千上万的if，永远无法超越创造者，
并且需要耗费大量的人力。

那什么是Machine Learning?
**Machine Learning≈Looking for a function**
![](/img/lhy_ml/2.png)  
1. 找一个f的集合，也就是模型
2. 让机器能够根据数据衡量一个f的好坏，通过loss function：输入f输出它的好坏，L(f)=L(w,b)
3. 挑选出最好的f
![](/img/lhy_ml/3.png)  
蓝色部分是scenaio(方案)，是由问题决定的，能用有监督就不应该用强化学习，红色部分是在方案下所选择的task，
绿色部分是每种task下可用的解决方法

## 1. Regression
#### 1.1 Regression Example
提出一个回归问题：  
![](/img/lhy_ml/4.png)   
* 第一步，找一个Model  
![](/img/lhy_ml/5.png)   

* 第二步，衡量f的好坏  
![](/img/lhy_ml/6.png)  
用loss function L来衡量f，L的输入是f，输出是f的好坏，由于f是由w,b构成的，也可以写成L(w,b)，所以f越好就是希望L越小，
使得L最小的f/ w,b记为f*/ w*,b*  

* 第三步，选择最好的f  
对于线性回归可以使用线性代数知识直接计算L的最小值，但无法直接计算其他问题    
在有了L之后只要对输入可以进行微分，就可以使用gradient descent来求解L的最小值  
![](/img/lhy_ml/7.png)   
gradient descent：随机w0,b0，计算L关于w,b的微分(切线斜率)，如果斜率为负，需要增大w，反之需要减小，所以我们将w,b向着梯度的反方向以学习率η倍数增加  

#### 1.2 gradient descent的问题
![](/img/lhy_ml/8.png)   
1. 无法保证找到的是global minima  
2. 有可能梯度=0时是saddle point  
3. 有时梯度非常小时，它可能只是一个离minima比较远的平滑的部分  
* 不过，线性回归问题的梯度都是碗型，不存在这些问题

#### 1.3 Regularization
* 更多model选择：  
![](/img/lhy_ml/9.png)   
更复杂的model在训练集上可以获得更小的error
![](/img/lhy_ml/10.png)   
但是在测试集上可能表现不好，出现overfitting现象  

* 解决办法：
1. 重新设计model  
![](/img/lhy_ml/11.png) 
![](/img/lhy_ml/12.png)   
这个model仍然是linear model，linear model是指参数对于output是否是线性，同理b+w1x1+w2x1<sup>2</sup>也是线性模型  

2. 正则化
![](/img/lhy_ml/13.png)   
* 正则化修改了L，在原来的基础上增加了一项，要求Lmin就是希望原来loss小的同时要选w很小的f，也就是平滑的f，平滑意味着输入有变化时，输出变化小，之所以要这样要求是因为多数情况下平滑的f更可能是较好的f  
* 为什么不对b正则化？因为b本身是一条直线，对f的平滑程度无影响，对它正则化就是要求b接近0  
* λ越大，f越平滑， 一般对λ取值0.01~0.05之间  

#### 1.4 Underfitting and Overfitting
![](/img/lhy_ml/14.png)   
把真正的f<sup>^</sup>看作靶心，其他f看作靶的其他位置，bias、variance如图，一个model是很多f的集合，也就是靶上的一个范围，不同数据同一个model下会找到不同的f* ，也就是在这个范围里选不同的f做f* ，如果这个model比较复杂，那就是它的范围就会比较大，这个大的范围更有可能包含真正的靶心f<sup>^</sup>，在这个范围里的f* 的平均情况下得到的f<sup>-</sup>会更接近f<sup>^</sup>，也就是瞄的比较准，bias比较小，但是由于范围大，f* 可能会散落在整个范围的各个位置，导致variance比较大，同理，简单的model范围小，bias较大，variance较小
![](/img/lhy_ml/15.png)   
error(E<sub>out</sub>)由bias和variance构成，如果错误主要来源于bias，说明underfitting，如果主要来源于variance说明overfitting，也就是说，如果model不能fit训练集，那么有较大的bias->underfitting，如果可以fit训练集但是在测试集上有较大误差，那么有较大的variance->overfitting，通过知道error的来源，来提升model    
* 如果underfitting，那么增加模型复杂度、增加更多features作为输入
* 如果overfitting，那么加大数据(自己造数据等方法)、正则化，但正则化可能会伤害到bias

#### 1.5 Model Selection
![](/img/lhy_ml/16.png)   
如果直接用测试集选模型，就污染了测试集，在测试集上的表现就不能体现真实外部表现，应该用验证集选择模型，这时选出的模型在测试集上的表现更能近似外部情况，验证集选择模型后可用所有训练数据再次训练选好的模型。为防止训练集测试集划分带来的问题，可以使用交叉验证N-fold Cross Validation的方法

#### 1.6 Summary
1. 选择一个model
2. 判断一个f好坏/选择一个Loss functiong
3. 选出一个f* ：梯度下降 
4. 验证集验证，根据验证集与训练集的error情况，判断是underfitting还是overfitting，回1








