---
layout:     post
title:      "Semi-supervised Learning"
subtitle:   "Introduction"
date:       2019-08-06
author:     "btyzkelili"
header-img: "img/post-bg-nextgen-web-pwa.jpg"
header-mask: 0.3
catalog:    true
tags:
    - Deep Learning
---  
## 1. Introduction
![](/img/lhy_ml/ssl-1.png)  ![](/img/lhy_ml/ssl-2.png)  
我们不缺数据，缺的是有标签的数据，没有标签的数据分布会隐含一些信息，基于一些假设，我们可以从没有标签的数据上学习到一些知识

## 2. Semi-supervied for Generative Model
![](/img/lhy_ml/ssl-3.png)  
无标签数据可能是class1可能是class2，用有标签数据训练出来的model对无标签数据判决它是class1和class2的可能性，用这个可能性更新model

## 3. Assumption

### 1. Low-density Separation "非黑即白"

#### self-training
![](/img/lhy_ml/ssl-4.png)  
self-training对regression没有作用，因为regression预测一个实数，当前model对无标签数据得到的实数无法修正model
![](/img/lhy_ml/ssl-5.png)  
如果使用NN，对比generative model，Soft label的半监督是无效的，因为新model的到的目标是之前model的结果，是不会修正model的，而genrative model、
可以，因为generative model的参数是通过μ来更新的

#### Entropy-besed Regularization
![](/img/lhy_ml/ssl-6.png)  
Loss function希望无标签数据输出的属于某一类别的可能性尽可能集中，也就是E(y)越小越好，同时希望有标签数据尽可能符合标签结果

#### Semi-supervised SVM
![](/img/lhy_ml/ssl-7.png)  




